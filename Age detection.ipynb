{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import cv2\n",
    "from IPython.display import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    plt.imshow(img, interpolation='bicubic')\n",
    "    plt.xticks([]), plt.yticks([]) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onlyfiles = os.listdir(\"C:\\\\Users\\\\91870\\\\UTKFace\")\n",
    "y = np.array([[[int(i.split('_')[0])],[int(i.split('_')[1])]] for i in onlyfiles])\n",
    "# y = np.array([[i.split('_')[1] for i in onlyfiles]]).T\n",
    "print(y.shape)\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data =[]\n",
    "for file in onlyfiles:\n",
    "    face = cv2.imread(\"C:\\\\Users\\\\91870\\\\UTKFace\\\\\"+file,cv2.IMREAD_COLOR)\n",
    "    face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "    face =cv2.resize(face, (32,32) )\n",
    "    X_data.append(face)\n",
    "X_data=np.array(X_data)\n",
    "X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.squeeze(X_data)\n",
    "imshow(X[1])\n",
    "print(y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=[y_train[:,1],y_train[:,0]]\n",
    "y_valid=[y_valid[:,1],y_valid[:,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model():\n",
    "    inputs = tf.keras.layers.Input(shape=(32,32, 3))\n",
    "    x = inputs\n",
    "    x = layers.Conv2D(32,3,activation='relu')(x)\n",
    "    x = layers.Conv2D(32,3,activation='relu')(x)\n",
    "    x = layers.MaxPool2D(2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Conv2D(64,3,activation='relu')(x)\n",
    "    x = layers.Conv2D(64,3,activation='relu')(x)\n",
    "    x = layers.MaxPool2D(2)(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Conv2D(84,3,activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x1 = layers.Dense(64,activation='relu')(x)\n",
    "    x2 = layers.Dense(64,activation='relu')(x)\n",
    "    x1 = layers.Dense(1,activation='sigmoid',name='sex_out')(x1)\n",
    "    x2 = layers.Dense(1,activation='relu',name='age_out')(x2)\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=[x1, x2])\n",
    "    model.compile(optimizer='Adam', loss=['binary_crossentropy','mae'],metrics=['accuracy']) \n",
    "    return model\n",
    "model=gen_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadVggFaceModel():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.ZeroPadding2D(padding=(1,1), input_shape = (100,100, 3)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.ZeroPadding2D(padding=(1,1)),\n",
    "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D((2,2), strides=(2,2)),\n",
    "        \n",
    "        tf.keras.layers.ZeroPadding2D(padding=(1,1)),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.ZeroPadding2D(padding=(1,1)),\n",
    "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D((2,2), strides=(2,2)),\n",
    "        \n",
    "        tf.keras.layers.ZeroPadding2D(padding=(1,1)),\n",
    "        tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.ZeroPadding2D(padding=(1,1)),\n",
    "        tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.ZeroPadding2D(padding=(1,1)),\n",
    "        tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D((2,2), strides=(2,2)),\n",
    "        \n",
    "        tf.keras.layers.ZeroPadding2D(padding=(1,1)),\n",
    "        tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.ZeroPadding2D(padding=(1,1)),\n",
    "        tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.ZeroPadding2D(padding=(1,1)),\n",
    "        tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D((2,2), strides=(2,2)),\n",
    "        tf.keras.layers.ZeroPadding2D(padding=(1,1)),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.ZeroPadding2D(padding=(1,1)),\n",
    "        tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.ZeroPadding2D(padding=(1,1)),\n",
    "        tf.keras.layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D((2,2), strides=(2,2)),\n",
    "        \n",
    "        \n",
    "        tf.keras.layers.Conv2D(512, (3,3), activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Conv2D(117, (1,1), activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Activation('softmax')\n",
    "     ])\n",
    "mo=loadVggFaceModel()\n",
    "mo.compile(optimizer='Adam', loss=['binary_crossentropy','mae'],metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks \n",
    "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\",  \n",
    "                                        mode =\"min\", patience = 5,  \n",
    "                                        restore_best_weights = True)\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpoint = ModelCheckpoint(r\"C:\\Users\\91870\\check\",\n",
    "                             monitor='val_loss',\n",
    "                             mode='min',\n",
    "                             save_best_only=True,\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_id=random.random()\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=75, monitor='val_loss',restore_best_weights=True)\n",
    "]\n",
    "model.fit(X_train, y_train, epochs=300,batch_size=128,validation_data=(X_valid,y_valid),callbacks=[callbacks,checkpoint], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "mo = keras.models.load_model(\"C://Users//91870//asv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo.evaluate(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mo.predict(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt=X_valid[6754]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_id=6754\n",
    "imshow(X_valid[p_id])\n",
    "print(y_valid[0][p_id],y_valid[1][p_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt=rt[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0) #capture webcam\n",
    "\n",
    "while(True):\n",
    "\tret, img = cap.read()\n",
    "\t#img = cv2.resize(img, (640, 360))\n",
    "\tface_cascade = cv2.CascadeClassifier('C:\\opencv-master\\data\\haarcascades\\haarcascade_frontalface_default.xml')\n",
    "\tfaces = face_cascade.detectMultiScale(img, 1.3, 5)\n",
    "\t\n",
    "\tfor (x,y,w,h) in faces:\n",
    "\t\tif w > 130: #ignore small faces\n",
    "\t\t\t\n",
    "\t\t\t#mention detected face\n",
    "\t\t\t\"\"\"overlay = img.copy(); output = img.copy(); opacity = 0.6\n",
    "\t\t\tcv2.rectangle(img,(x,y),(x+w,y+h),(128,128,128),cv2.FILLED) #draw rectangle to main image\n",
    "\t\t\tcv2.addWeighted(overlay, opacity, img, 1 - opacity, 0, img)\"\"\"\n",
    "\t\t\tcv2.rectangle(img,(x,y),(x+w,y+h),(256,256,256),1) #draw rectangle to main image\n",
    "\t\t\t\n",
    "\t\t\t#extract detected face\n",
    "\t\t\tdetected_face = img[int(y):int(y+h), int(x):int(x+w)] #crop detected face\n",
    "\t\t\t\n",
    "\t\t\ttry:\n",
    "\t\t\t\t#age gender data set has 40% margin around the face. expand detected face.\n",
    "\t\t\t\tmargin = 30\n",
    "\t\t\t\tmargin_x = int((w * margin)/100); margin_y = int((h * margin)/100)\n",
    "\t\t\t\tdetected_face = img[int(y-margin_y):int(y+h+margin_y), int(x-margin_x):int(x+w+margin_x)]\n",
    "\t\t\texcept:\n",
    "\t\t\t\tprint(\"detected face has no margin\")\n",
    "\t\t\t\n",
    "\t\t\ttry:\n",
    "\t\t\t\t#vgg-face expects inputs (224, 224, 3)\n",
    "\t\t\t\tdetected_face = cv2.resize(detected_face, (32,32))\n",
    "\t\t\t\t\n",
    "\t\t\t\timg_pixels = image.img_to_array(detected_face)\n",
    "\t\t\t\timg_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "\n",
    "                \n",
    "\t\t\t\tinput_arr = np.array(img_pixels)\n",
    "\t\t\t\t#find out age and gender\n",
    "\t\t\t\tage_distributions = mo.predict(input_arr)\n",
    "\t\t\t\tapparent_age = str(int(age_distributions[1]))\n",
    "                \n",
    "\t\t\t\t\n",
    "\t\t\t\n",
    "\t\t\t\t#background for age gender declaration\n",
    "\t\t\t\tinfo_box_color = (254,233,255)\n",
    "\t\t\t\ttriangle_cnt = np.array( [(x+int(w/2), y+10), (x+int(w/2)-25, y-20), (x+int(w/2)+25, y-20)] )\n",
    "\t\t\t\ttriangle_cnt = np.array( [(x+int(w/2), y), (x+int(w/2)-20, y-20), (x+int(w/2)+20, y-20)] )\n",
    "\t\t\t\t\n",
    "\t\t\t\tcv2.rectangle(img,(x+int(w/2)-5,y-20),(x+int(w/2)+50,y-90),info_box_color,cv2.FILLED)\n",
    "\t\t\t\t\n",
    "\t\t\t\t#labels for age and gender\n",
    "\t\t\t\tcv2.putText(img, apparent_age, (x+int(w/2), y - 45), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 111, 255), 2)\n",
    "\t\t\t\t\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\t\n",
    "\t\t\n",
    "\t\t\t\t\t#cv2.putText(img,\"\", cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 111, 255), 2)\n",
    "\t\t\t\t\n",
    "\t\t\texcept Exception as e:\n",
    "\t\t\t\tprint(\"exception\",str(e))\n",
    "\t\t\t\n",
    "\tcv2.imshow('img',img)\n",
    "\n",
    "\tif 0xFF == ord('q') or apparent_age<'18': #press q to quit\n",
    "\t\tbreak\n",
    "\t\n",
    "\t\n",
    "#kill open cv things\t\t\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
