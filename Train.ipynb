{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import cv2 as cv\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2 \n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from imutils.video import VideoStream\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = '/Users/kunal/Desktop/Age-Detection/dataset'\n",
    "imagePaths = list(paths.list_images(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "for i in imagePaths:\n",
    "    label = i.split(os.path.sep)[-2]\n",
    "    labels.append(label)\n",
    "    image = load_img(i, target_size = (224, 224))\n",
    "    image = img_to_array(image)\n",
    "    image = preprocess_input(image)\n",
    "    data.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype = 'float32')\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(data, labels, test_size = 0.20, random_state = 10, stratify = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "baseModel = MobileNetV2(weights='imagenet', include_top=False, input_tensor= Input(shape = (224,224,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size = (5,5))(headModel)\n",
    "headModel = Flatten(name = 'Flatten')(headModel)\n",
    "headModel = Dense(128, activation = 'relu')(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation = 'softmax')(headModel)\n",
    "\n",
    "model = Model(inputs = baseModel.input, outputs = headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "882/882 [==============================] - 248s 278ms/step - loss: 0.4764 - accuracy: 0.8634 - val_loss: 0.2119 - val_accuracy: 0.9178\n",
      "Epoch 2/10\n",
      "882/882 [==============================] - 254s 288ms/step - loss: 0.2540 - accuracy: 0.8995 - val_loss: 0.1924 - val_accuracy: 0.9273\n",
      "Epoch 3/10\n",
      "882/882 [==============================] - 269s 305ms/step - loss: 0.2262 - accuracy: 0.9062 - val_loss: 0.1991 - val_accuracy: 0.9227\n",
      "Epoch 4/10\n",
      "882/882 [==============================] - 276s 313ms/step - loss: 0.2125 - accuracy: 0.9190 - val_loss: 0.1914 - val_accuracy: 0.9288\n",
      "Epoch 5/10\n",
      "882/882 [==============================] - 279s 317ms/step - loss: 0.1976 - accuracy: 0.9237 - val_loss: 0.1897 - val_accuracy: 0.9250\n",
      "Epoch 6/10\n",
      "882/882 [==============================] - 284s 322ms/step - loss: 0.1987 - accuracy: 0.9228 - val_loss: 0.1899 - val_accuracy: 0.9295\n",
      "Epoch 7/10\n",
      "882/882 [==============================] - 286s 325ms/step - loss: 0.1770 - accuracy: 0.9281 - val_loss: 0.1831 - val_accuracy: 0.9299\n",
      "Epoch 8/10\n",
      "882/882 [==============================] - 292s 332ms/step - loss: 0.1690 - accuracy: 0.9347 - val_loss: 0.1865 - val_accuracy: 0.9318\n",
      "Epoch 9/10\n",
      "882/882 [==============================] - 297s 337ms/step - loss: 0.1517 - accuracy: 0.9407 - val_loss: 0.1839 - val_accuracy: 0.9303\n",
      "Epoch 10/10\n",
      "882/882 [==============================] - 300s 340ms/step - loss: 0.1643 - accuracy: 0.9354 - val_loss: 0.1942 - val_accuracy: 0.9269\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "Epochs = 10\n",
    "batch_size = 12\n",
    "\n",
    "opt = Adam(lr=learning_rate, decay = learning_rate/Epochs)\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy', optimizer = opt, metrics = ['accuracy'])\n",
    "\n",
    "H = model.fit(\n",
    "    train_X, train_Y, batch_size = batch_size,\n",
    "    steps_per_epoch=len(train_X)//batch_size,\n",
    "    validation_data=(test_X, test_Y),\n",
    "    validation_steps=len(test_X)//batch_size,\n",
    "    epochs = Epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model3.model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model3.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
